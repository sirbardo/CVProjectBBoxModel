{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageDraw\n",
    "from skimage.transform import resize\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "labels = []\n",
    "\n",
    "for i in tqdm(range(256)):\n",
    "    scale_factors = []\n",
    "    filenames = glob.glob('UECFOOD256/' + str(i+1) + '/*.jpg') # all files in the folder that are jpg\n",
    "    filenames.sort() #lexicographically \n",
    "    list_of_numbers = [item.split('\\\\')[1].split('.')[0] for item in filenames]\n",
    "    list_of_numbers = list(map(int, list_of_numbers))\n",
    "    for filename in filenames:\n",
    "        with Image.open(filename) as im:\n",
    "            #im = cv2.imread(im)\n",
    "            im = np.array(im)\n",
    "            scale_factors += [(224/im.shape[1], 224/im.shape[0])]\n",
    "            im = cv2.resize(im, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "            image_list.append(im)\n",
    "    \n",
    "    \n",
    "    with open('UECFOOD256/' + str(i+1) + '/bb_info.txt', 'r') as file:\n",
    "        \n",
    "        listOfLabels = file.readlines()[1:]\n",
    "        listOfLabels.sort()\n",
    "        \n",
    "        seen = set()\n",
    "        result = []\n",
    "        for item in listOfLabels:\n",
    "            if item.split()[0] not in seen:\n",
    "                seen.add(item.split()[0])\n",
    "                result.append(item)\n",
    "\n",
    "        indices = [item.split()[0] for item in result]                \n",
    "        \n",
    "        j = 0\n",
    "        for line in result:\n",
    "            temp = list(map(int, line.split()[1:]))\n",
    "            temp = [temp[0]*scale_factors[j][0], temp[1]*scale_factors[j][1], temp[2]*scale_factors[j][0], temp[3]*scale_factors[j][1]]\n",
    "            labels.append(temp)\n",
    "            j+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = image_list[9].reshape((224,224,3))\n",
    "prova = Image.fromarray(prova)\n",
    "prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(image_list): #get rid of jpgs with alpha values\n",
    "    if item.shape != (224, 224, 3):\n",
    "        image_list[idx] = image_list[idx][:,:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = np.array(image_list)\n",
    "#image_list = image_list.astype('float16')\n",
    "#image_list = image_list / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8000\n",
    "prova = Image.fromarray(image_list[k])\n",
    "drawing = ImageDraw.Draw(prova)\n",
    "drawing.rectangle(list(labels[k]))\n",
    "prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_list.shape)\n",
    "image_list = image_list.reshape((image_list.shape[0],224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.activations import relu\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "check = keras.callbacks.ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=50, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (1, 1), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (1, 1), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (1, 1), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4))\n",
    "\n",
    "model.compile(loss='mse', optimizer='nadam', metrics=['mean_squared_error'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(image_list, labels, epochs=100, batch_size=50, verbose=1, callbacks=[check], validation_split=.1)\n",
    "# Final evaluation of the model\n",
    "#scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "#print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in tqdm(range(0,2)):\n",
    "    scale_factors = []\n",
    "    filenames = glob.glob('UECFOOD256/' + str(i+1) + '/*.jpg') # all files in the folder that are jpg\n",
    "    filenames.sort() #lexicographically \n",
    "    list_of_numbers = [item.split('\\\\')[1].split('.')[0] for item in filenames]\n",
    "    list_of_numbers = list(map(int, list_of_numbers))\n",
    "    for filename in filenames:\n",
    "        with Image.open(filename) as im:\n",
    "            #im = cv2.imread(im)\n",
    "            im = np.array(im)\n",
    "            scale_factors += [(300/im.shape[1], 300/im.shape[0])]\n",
    "            im = cv2.resize(im, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "            x_test.append(im)\n",
    "    \n",
    "    \n",
    "    with open('UECFOOD256/' + str(i+1) + '/bb_info.txt', 'r') as file:\n",
    "        \n",
    "        listOfLabels = file.readlines()[1:]\n",
    "        listOfLabels.sort()\n",
    "        \n",
    "        seen = set()\n",
    "        result = []\n",
    "        for item in listOfLabels:\n",
    "            if item.split()[0] not in seen:\n",
    "                seen.add(item.split()[0])\n",
    "                result.append(item)\n",
    "\n",
    "        indices = [item.split()[0] for item in result]                \n",
    "        \n",
    "        j = 0\n",
    "        for line in result:\n",
    "            temp = list(map(int, line.split()[1:]))\n",
    "            temp = [temp[0]*scale_factors[j][0], temp[1]*scale_factors[j][1], temp[2]*scale_factors[j][0], temp[3]*scale_factors[j][1]]\n",
    "            y_test.append(temp)\n",
    "            j+=1\n",
    "            \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights.06-150.60.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 58\n",
    "prova_result = model.predict(np.array([x_test[index].reshape(224,224,3)]))\n",
    "prova = Image.fromarray(x_test[index])\n",
    "drawing = ImageDraw.Draw(prova)\n",
    "drawing.rectangle(prova_result)\n",
    "print(prova_result)\n",
    "prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
